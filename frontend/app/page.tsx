'use client';

import { useState, useRef, useEffect } from 'react';

interface ChatMessage {
  user: string;
  ai: string;
  timestamp: string;
}

interface SystemStatus {
  ollama_connected: boolean;
  microphone_available: boolean;
  speaker_available: boolean;
  available_voices: number;
  available_microphones: number;
}

export default function Home() {
  const [isRecording, setIsRecording] = useState(false);
  const [textInput, setTextInput] = useState('');
  const [conversation, setConversation] = useState<ChatMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [systemStatus, setSystemStatus] = useState<SystemStatus | null>(null);
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null);
  const [debugMode, setDebugMode] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);

  const API_BASE = 'http://localhost:8000';

  // ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’å–å¾—
  useEffect(() => {
    checkSystemStatus();
    
    // ãƒ–ãƒ©ã‚¦ã‚¶ã®éŸ³å£°ã‚µãƒãƒ¼ãƒˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    console.log('MediaRecorder support check:');
    console.log('audio/wav:', MediaRecorder.isTypeSupported('audio/wav'));
    console.log('audio/webm:', MediaRecorder.isTypeSupported('audio/webm'));
    console.log('audio/webm;codecs=opus:', MediaRecorder.isTypeSupported('audio/webm;codecs=opus'));
    console.log('audio/mp4:', MediaRecorder.isTypeSupported('audio/mp4'));
    console.log('audio/ogg;codecs=opus:', MediaRecorder.isTypeSupported('audio/ogg;codecs=opus'));
    
    // Web Speech API ã®ã‚µãƒãƒ¼ãƒˆç¢ºèª
    console.log('Web Speech API support:');
    console.log('SpeechRecognition:', 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window);
    console.log('SpeechSynthesis:', 'speechSynthesis' in window);
    
    // éŸ³å£°åˆæˆã®å£°ã‚’ãƒ­ãƒ¼ãƒ‰
    if ('speechSynthesis' in window) {
      const loadVoices = () => {
        const voices = window.speechSynthesis.getVoices();
        console.log('åˆ©ç”¨å¯èƒ½ãªéŸ³å£°:', voices.length);
        voices.forEach(voice => {
          if (voice.lang.startsWith('en')) {
            console.log(`è‹±èªéŸ³å£°: ${voice.name} (${voice.lang})`);
          }
        });
      };
      
      if (window.speechSynthesis.getVoices().length > 0) {
        loadVoices();
      } else {
        window.speechSynthesis.onvoiceschanged = loadVoices;
      }
    }
  }, []);

  const checkSystemStatus = async () => {
    try {
      const response = await fetch(`${API_BASE}/system/status`);
      const status = await response.json();
      setSystemStatus(status);
    } catch (error) {
      console.error('ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
  const requestMicrophoneAccess = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setAudioStream(stream);
      return stream;
    } catch (error) {
      console.error('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      return null;
    }
  };

  // WebAudio APIã‚’ä½¿ç”¨ã—ã¦WAVå½¢å¼ã§éŒ²éŸ³
  const startRecording = async () => {
    const stream = audioStream || await requestMicrophoneAccess();
    if (!stream) return;

    try {
      // AudioContextã‚’ä½œæˆ
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      let audioData: Float32Array[] = [];
      
      processor.onaudioprocess = (event) => {
        const inputData = event.inputBuffer.getChannelData(0);
        audioData.push(new Float32Array(inputData));
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      
      // éŒ²éŸ³åœæ­¢æ™‚ã®å‡¦ç†ã‚’è¨­å®š
      const stopRecordingInternal = () => {
        processor.disconnect();
        source.disconnect();
        audioContext.close();
        
        // Float32Arrayã‚’WAVãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›
        const wavBlob = createWavBlob(audioData, audioContext.sampleRate);
        console.log(`WAV blob created: size=${wavBlob.size}, type=${wavBlob.type}`);
        
        if (wavBlob.size === 0) {
          alert('éŸ³å£°ãŒéŒ²éŸ³ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒã‚¤ã‚¯ã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
          return;
        }
        
        processSpeechChat(wavBlob, 'wav');
      };
      
      // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åœæ­¢é–¢æ•°ã‚’ä¿å­˜
      (window as any).stopRecordingInternal = stopRecordingInternal;
      
      setIsRecording(true);
      console.log('WAVéŒ²éŸ³é–‹å§‹');
      
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      alert('éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  };

  // Float32Arrayã‹ã‚‰WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
  const createWavBlob = (audioData: Float32Array[], sampleRate: number): Blob => {
    const length = audioData.reduce((acc, chunk) => acc + chunk.length, 0);
    
    if (length === 0) {
      console.error('éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™');
      return new Blob([], { type: 'audio/wav' });
    }
    
    console.log(`WAVä½œæˆ: ã‚µãƒ³ãƒ—ãƒ«æ•°=${length}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ=${sampleRate}Hz, é•·ã•=${length/sampleRate}ç§’`);
    
    const buffer = new ArrayBuffer(44 + length * 2);
    const view = new DataView(buffer);
    
    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã¿ï¼ˆ16bit PCM, ãƒ¢ãƒãƒ©ãƒ«ï¼‰
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * 2, true);  // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º - 8
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);              // PCMãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚µã‚¤ã‚º
    view.setUint16(20, 1, true);               // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¿ã‚¤ãƒ—ï¼ˆPCMï¼‰
    view.setUint16(22, 1, true);               // ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼ˆãƒ¢ãƒãƒ©ãƒ«ï¼‰
    view.setUint32(24, sampleRate, true);      // ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
    view.setUint32(28, sampleRate * 2, true);  // ãƒã‚¤ãƒˆãƒ¬ãƒ¼ãƒˆ
    view.setUint16(32, 2, true);               // ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ
    view.setUint16(34, 16, true);              // ãƒ“ãƒƒãƒˆæ·±åº¦
    writeString(36, 'data');
    view.setUint32(40, length * 2, true);      // ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
    
    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆ16bitï¼‰
    let offset = 44;
    for (const chunk of audioData) {
      for (let i = 0; i < chunk.length; i++) {
        const sample = Math.max(-1, Math.min(1, chunk[i]));
        view.setInt16(offset, sample * 0x7FFF, true);
        offset += 2;
      }
    }
    
    console.log(`WAVãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: ${buffer.byteLength} bytes`);
    return new Blob([buffer], { type: 'audio/wav' });
  };

  // éŸ³å£°éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    if ((window as any).stopRecordingInternal) {
      (window as any).stopRecordingInternal();
      (window as any).stopRecordingInternal = null;
    }
    setIsRecording(false);
  };

  // éŸ³å£°ãƒãƒ£ãƒƒãƒˆå‡¦ç†
  const processSpeechChat = async (audioBlob: Blob, fileExtension: string = 'webm') => {
    setIsLoading(true);
    try {
      const formData = new FormData();
      formData.append('audio_file', audioBlob, `recording.${fileExtension}`);

      const response = await fetch(`${API_BASE}/speech/chat`, {
        method: 'POST',
        body: formData,
      });

      if (response.ok) {
        const result = await response.json();
        const newMessage: ChatMessage = {
          user: result.user_text,
          ai: result.ai_response,
          timestamp: new Date().toLocaleTimeString(),
        };
        setConversation(prev => [...prev, newMessage]);

        // AIå¿œç­”ã‚’éŸ³å£°ã§å†ç”Ÿ
        if (result.ai_response) {
          console.log('AIå¿œç­”ã®éŸ³å£°å†ç”Ÿé–‹å§‹:', result.ai_response);
          await playTextToSpeech(result.ai_response);
          console.log('AIå¿œç­”ã®éŸ³å£°å†ç”Ÿå®Œäº†');
        }
      } else {
        const errorData = await response.text();
        console.error('éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼è©³ç´°:', errorData);
        alert(`éŸ³å£°å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${errorData}`);
      }
    } catch (error) {
      console.error('éŸ³å£°ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼:', error);
      alert(`éŸ³å£°å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : String(error)}`);
    } finally {
      setIsLoading(false);
    }
  };

  // ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆ
  const processTextChat = async () => {
    if (!textInput.trim()) return;

    setIsLoading(true);
    try {
      const response = await fetch(`${API_BASE}/chat/text`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text: textInput }),
      });

      if (response.ok) {
        const result = await response.json();
        const newMessage: ChatMessage = {
          user: textInput,
          ai: result.response,
          timestamp: new Date().toLocaleTimeString(),
        };
        setConversation(prev => [...prev, newMessage]);
        setTextInput('');

        // AIå¿œç­”ã‚’éŸ³å£°ã§å†ç”Ÿ
        if (result.response) {
          await playTextToSpeech(result.response);
        }
      } else {
        alert('ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
      }
    } catch (error) {
      console.error('ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    } finally {
      setIsLoading(false);
    }
  };

  // éŸ³å£°åˆæˆãƒ»å†ç”Ÿï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã®Web Speech APIä½¿ç”¨ï¼‰
  const playTextToSpeech = async (text: string) => {
    try {
      console.log('TTSé–‹å§‹ï¼ˆWeb Speech APIä½¿ç”¨ï¼‰:', text);
      
      // ç¾åœ¨ã®éŸ³å£°ã‚’åœæ­¢
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }
      
      // Web Speech APIãŒä½¿ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
      if ('speechSynthesis' in window) {
        // ç¾åœ¨ã®ç™ºè©±ã‚’åœæ­¢
        window.speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        
        // è‹±èªéŸ³å£°ã‚’è¨­å®š
        const voices = window.speechSynthesis.getVoices();
        const englishVoice = voices.find(voice => 
          voice.lang.startsWith('en') && 
          (voice.name.includes('English') || voice.name.includes('US') || voice.name.includes('GB'))
        );
        
        if (englishVoice) {
          utterance.voice = englishVoice;
          console.log('ä½¿ç”¨ã™ã‚‹éŸ³å£°:', englishVoice.name, englishVoice.lang);
        }
        
        // éŸ³å£°è¨­å®š
        utterance.rate = 0.9;    // è©±é€Ÿ
        utterance.pitch = 1.0;   // éŸ³ç¨‹
        utterance.volume = 0.8;  // éŸ³é‡
        
        // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
        utterance.onstart = () => {
          console.log('éŸ³å£°å†ç”Ÿé–‹å§‹');
          setIsPlaying(true);
        };
        utterance.onend = () => {
          console.log('éŸ³å£°å†ç”Ÿçµ‚äº†');
          setIsPlaying(false);
        };
        utterance.onerror = (e) => {
          console.error('éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼:', e);
          setIsPlaying(false);
        };
        
        // éŸ³å£°å†ç”Ÿ
        window.speechSynthesis.speak(utterance);
      } else {
        console.error('Web Speech APIï¼ˆéŸ³å£°åˆæˆï¼‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“');
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ¼ãƒãƒ¼TTSã‚’è©¦è¡Œ
        await playTextToSpeechFallback(text);
      }
    } catch (error) {
      console.error('éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
      setIsPlaying(false);
    }
  };

  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ¼ãƒãƒ¼TTS
  const playTextToSpeechFallback = async (text: string) => {
    try {
      console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯TTSé–‹å§‹:', text);
      const response = await fetch(`${API_BASE}/speech/synthesize`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text }),
      });

      if (response.ok) {
        const audioBlob = await response.blob();
        console.log('TTSéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡:', audioBlob.size, 'bytes, type:', audioBlob.type);
        
        if (audioBlob.size === 0) {
          console.error('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™');
          return;
        }
        
        // ç¾åœ¨å†ç”Ÿä¸­ã®éŸ³å£°ãŒã‚ã‚Œã°åœæ­¢
        if (currentAudioRef.current) {
          currentAudioRef.current.pause();
          currentAudioRef.current = null;
        }
        
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        currentAudioRef.current = audio;
        
        audio.onloadeddata = () => console.log('éŸ³å£°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†');
        audio.onplay = () => {
          console.log('éŸ³å£°å†ç”Ÿé–‹å§‹');
          setIsPlaying(true);
        };
        audio.onended = () => {
          console.log('éŸ³å£°å†ç”Ÿçµ‚äº†');
          setIsPlaying(false);
          URL.revokeObjectURL(audioUrl);
          currentAudioRef.current = null;
        };
        audio.onerror = (e) => {
          console.error('éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼:', e);
          setIsPlaying(false);
          currentAudioRef.current = null;
        };
        
        await audio.play();
      } else {
        const errorText = await response.text();
        console.error('TTS APIã‚¨ãƒ©ãƒ¼:', response.status, errorText);
      }
    } catch (error) {
      console.error('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯TTS ã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢
  const clearConversation = async () => {
    try {
      await fetch(`${API_BASE}/conversation/history`, { method: 'DELETE' });
      setConversation([]);
    } catch (error) {
      console.error('å±¥æ­´ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆ
  const testSpeaker = async () => {
    try {
      const response = await fetch(`${API_BASE}/test/speaker`);
      if (response.ok) {
        const audioBlob = await response.blob();
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        audio.play();
      }
    } catch (error) {
      console.error('ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
  const testAudioUpload = async (audioBlob: Blob, fileExtension: string) => {
    try {
      const formData = new FormData();
      formData.append('audio_file', audioBlob, `test.${fileExtension}`);
      
      const response = await fetch(`${API_BASE}/test/upload`, {
        method: 'POST',
        body: formData,
      });
      
      const result = await response.json();
      console.log('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆçµæœ:', result);
      return result;
    } catch (error) {
      console.error('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:', error);
      return null;
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 p-4">
      <div className="max-w-6xl mx-auto">
        {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
        <div className="text-center mb-8">
          <h1 className="text-4xl font-bold text-gray-800 mb-2">
            ğŸ¤ AIéŸ³å£°è‹±ä¼šè©±ã‚¢ãƒ—ãƒª
          </h1>
          <p className="text-lg text-gray-600">
            éŸ³å£°ã§AIã¨è‹±èªä¼šè©±ã‚’ç·´ç¿’ã—ã‚ˆã†ï¼
          </p>
        </div>

        {/* ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ */}
        {systemStatus && (
          <div className="bg-white rounded-lg shadow-md p-4 mb-6">
            <h2 className="text-xl font-semibold mb-3">ğŸ› ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹</h2>
            <div className="grid grid-cols-2 md:grid-cols-5 gap-4 text-sm">
              <div className={`p-2 rounded ${systemStatus.ollama_connected ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'}`}>
                <div>Ollama</div>
                <div>{systemStatus.ollama_connected ? 'âœ… æ¥ç¶š' : 'âŒ æœªæ¥ç¶š'}</div>
              </div>
              <div className={`p-2 rounded ${systemStatus.microphone_available ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'}`}>
                <div>ãƒã‚¤ã‚¯</div>
                <div>{systemStatus.microphone_available ? 'âœ… åˆ©ç”¨å¯èƒ½' : 'âŒ æœªåˆ©ç”¨'}</div>
              </div>
              <div className={`p-2 rounded ${systemStatus.speaker_available ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'}`}>
                <div>ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼</div>
                <div>{systemStatus.speaker_available ? 'âœ… åˆ©ç”¨å¯èƒ½' : 'âŒ æœªåˆ©ç”¨'}</div>
              </div>
              <div className="p-2 rounded bg-blue-100 text-blue-800">
                <div>éŸ³å£°ç¨®é¡</div>
                <div>{systemStatus.available_voices}ç¨®é¡</div>
              </div>
              <div className="p-2 rounded bg-blue-100 text-blue-800">
                <div>ãƒã‚¤ã‚¯æ•°</div>
                <div>{systemStatus.available_microphones}å€‹</div>
              </div>
            </div>
            <div className="mt-3 flex gap-2">
              <button
                onClick={checkSystemStatus}
                className="px-3 py-1 bg-blue-500 text-white rounded hover:bg-blue-600"
              >
                ğŸ”„ çŠ¶æ…‹æ›´æ–°
              </button>
              <button
                onClick={testSpeaker}
                className="px-3 py-1 bg-green-500 text-white rounded hover:bg-green-600"
              >
                ğŸ”Š ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆ
              </button>
              <button
                onClick={() => setDebugMode(!debugMode)}
                className="px-3 py-1 bg-purple-500 text-white rounded hover:bg-purple-600"
              >
                ğŸ› {debugMode ? 'ãƒ‡ãƒãƒƒã‚°OFF' : 'ãƒ‡ãƒãƒƒã‚°ON'}
              </button>
            </div>
          </div>
        )}

        {debugMode && (
          <div className="bg-yellow-50 rounded-lg shadow-md p-4 mb-6">
            <h2 className="text-xl font-semibold mb-3">ğŸ› ãƒ‡ãƒãƒƒã‚°æƒ…å ±</h2>
            <div className="text-sm space-y-1">
              <div><strong>éŸ³å£°éŒ²éŸ³:</strong></div>
              <div>ã€€MediaRecorder.isTypeSupported('audio/wav'): {MediaRecorder.isTypeSupported('audio/wav').toString()}</div>
              <div>ã€€MediaRecorder.isTypeSupported('audio/webm'): {MediaRecorder.isTypeSupported('audio/webm').toString()}</div>
              <div>ã€€MediaRecorder.isTypeSupported('audio/webm;codecs=opus'): {MediaRecorder.isTypeSupported('audio/webm;codecs=opus').toString()}</div>
              <div>ã€€ç¾åœ¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ : {audioStream ? 'æœ‰åŠ¹' : 'ç„¡åŠ¹'}</div>
              <div><strong>éŸ³å£°å†ç”Ÿ:</strong></div>
              <div>ã€€SpeechSynthesis API: {'speechSynthesis' in window ? 'å¯¾å¿œ' : 'æœªå¯¾å¿œ'}</div>
              <div>ã€€åˆ©ç”¨å¯èƒ½ãªéŸ³å£°æ•°: {typeof window !== 'undefined' && 'speechSynthesis' in window ? window.speechSynthesis.getVoices().length : 0}</div>
              <div>ã€€è‹±èªéŸ³å£°: {typeof window !== 'undefined' && 'speechSynthesis' in window ? 
                window.speechSynthesis.getVoices().filter(v => v.lang.startsWith('en')).length : 0}å€‹</div>
            </div>
          </div>
        )}

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-6">
          {/* éŸ³å£°ä¼šè©±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ */}
          <div className="bg-white rounded-lg shadow-md p-6">
            <h2 className="text-2xl font-semibold mb-4">ğŸ™ï¸ éŸ³å£°ä¼šè©±</h2>
            <div className="space-y-4">
              <button
                onClick={isRecording ? stopRecording : startRecording}
                disabled={isLoading}
                className={`w-full py-3 px-6 rounded-lg font-semibold transition-colors ${ 
                  isRecording 
                    ? 'bg-red-500 hover:bg-red-600 text-white' 
                    : 'bg-blue-500 hover:bg-blue-600 text-white'
                } disabled:opacity-50`}
              >
                {isRecording ? 'â¹ï¸ éŒ²éŸ³åœæ­¢' : 'ğŸ¤ éŒ²éŸ³é–‹å§‹'}
              </button>
              {isRecording && (
                <div className="text-center text-red-600 font-medium">
                  ğŸ”´ éŒ²éŸ³ä¸­... è‹±èªã§è©±ã—ã¦ãã ã•ã„
                </div>
              )}
              {isLoading && (
                <div className="text-center text-blue-600 font-medium">
                  â³ å‡¦ç†ä¸­...
                </div>
              )}
              {isPlaying && (
                <div className="text-center text-green-600 font-medium">
                  ğŸ”Š éŸ³å£°å†ç”Ÿä¸­...
                </div>
              )}
            </div>
          </div>

          {/* ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ */}
          <div className="bg-white rounded-lg shadow-md p-6">
            <h2 className="text-2xl font-semibold mb-4">ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±</h2>
            <div className="space-y-4">
              <input
                type="text"
                value={textInput}
                onChange={(e) => setTextInput(e.target.value)}
                onKeyPress={(e) => e.key === 'Enter' && processTextChat()}
                placeholder="è‹±èªã§å…¥åŠ›ã—ã¦ãã ã•ã„..."
                className="w-full p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
              />
              <button
                onClick={processTextChat}
                disabled={isLoading || !textInput.trim()}
                className="w-full py-3 px-6 bg-green-500 hover:bg-green-600 text-white rounded-lg font-semibold disabled:opacity-50"
              >
                ğŸ“¤ é€ä¿¡
              </button>
            </div>
          </div>
        </div>

        {/* ä¼šè©±å±¥æ­´ */}
        <div className="bg-white rounded-lg shadow-md p-6">
          <div className="flex justify-between items-center mb-4">
            <h2 className="text-2xl font-semibold">ğŸ“ ä¼šè©±å±¥æ­´</h2>
            <button
              onClick={clearConversation}
              className="px-4 py-2 bg-red-500 hover:bg-red-600 text-white rounded-lg"
            >
              ğŸ—‘ï¸ ã‚¯ãƒªã‚¢
            </button>
          </div>
          
          {conversation.length === 0 ? (
            <div className="text-center text-gray-500 py-8">
              ã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã§è©±ã—ã‹ã‘ã¦ã¿ã¾ã—ã‚‡ã†ï¼
            </div>
          ) : (
            <div className="space-y-4 max-h-96 overflow-y-auto">
              {conversation.map((msg, index) => (
                <div key={index} className="border-b border-gray-200 pb-4">
                  <div className="mb-2">
                    <span className="font-medium text-blue-600">ğŸ‘¤ ã‚ãªãŸ:</span>
                    <span className="ml-2">{msg.user}</span>
                    <button
                      onClick={() => playTextToSpeech(msg.user)}
                      className="ml-2 text-sm text-blue-500 hover:text-blue-700"
                    >
                      ğŸ”Š
                    </button>
                  </div>
                  <div className="mb-1">
                    <span className="font-medium text-green-600">ğŸ¤– AI:</span>
                    <span className="ml-2">{msg.ai}</span>
                    <button
                      onClick={() => playTextToSpeech(msg.ai)}
                      className="ml-2 text-sm text-green-500 hover:text-green-700"
                    >
                      ğŸ”Š
                    </button>
                  </div>
                  <div className="text-xs text-gray-400">
                    {msg.timestamp}
                  </div>
                </div>
              ))}
            </div>
          )}
        </div>
      </div>
    </div>
  );
}
