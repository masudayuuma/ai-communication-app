# version: '3.9'  # obsolete attribute removed

services:
  # Redis - 音声・テキストパイプライン (Redis Streams)
  redis:
    image: redis:7-alpine
    container_name: ai-chat-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - ai-chat
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Whisper ASRサービス - faster-whisper使用
  whisper:
    build:
      context: .
      dockerfile: docker/Dockerfile.whisper
    container_name: ai-chat-whisper
    ports:
      - "8001:8001"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - REDIS_URL=redis://redis:6379
      - WHISPER_MODEL_SIZE=base
      - DEVICE=cpu
    volumes:
      - whisper_models:/models
      - ./services/whisper:/app
    networks:
      - ai-chat
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Llama-3 LLMサービス - Ollama統合
  llm:
    build:
      context: .
      dockerfile: docker/Dockerfile.llm
    container_name: ai-chat-llm
    ports:
      - "8002:8002"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - REDIS_URL=redis://redis:6379
      - OLLAMA_HOST=0.0.0.0:11434
    volumes:
      - llm_models:/root/.ollama
      - ./services/llm:/app
    networks:
      - ai-chat
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 180s
    restart: unless-stopped

  # XTTS-v2 TTSサービス - Coqui XTTS使用
  tts:
    build:
      context: .
      dockerfile: docker/Dockerfile.tts
    container_name: ai-chat-tts
    ports:
      - "8003:8003"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - REDIS_URL=redis://redis:6379
      - DEVICE=cpu
    volumes:
      - tts_models:/models
      - ./services/tts:/app
    networks:
      - ai-chat
    restart: unless-stopped

  # FastAPI Backend - 統合APIゲートウェイ
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile.backend
    container_name: ai-chat-backend
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
      whisper:
        condition: service_healthy
      llm:
        condition: service_healthy
      tts:
        condition: service_healthy
    environment:
      - REDIS_URL=redis://redis:6379
      - WHISPER_SERVICE_URL=http://whisper:8001
      - LLM_SERVICE_URL=http://llm:8002
      - TTS_SERVICE_URL=http://tts:8003
      - LOG_LEVEL=INFO
      - PYTHONPATH=/app
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    networks:
      - ai-chat
    restart: unless-stopped

  # Next.js Frontend - リアルタイムUI
  frontend:
    build:
      context: .
      dockerfile: docker/Dockerfile.frontend
    container_name: ai-chat-frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    networks:
      - ai-chat
    restart: unless-stopped

  # Prometheus - メトリクス収集 (開発時用)
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-chat-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-chat
    restart: unless-stopped
    profiles:
      - monitoring

networks:
  ai-chat:
    driver: bridge
    name: ai-chat-network

volumes:
  redis_data:
    driver: local
  whisper_models:
    driver: local
  llm_models:
    driver: local
  tts_models:
    driver: local
  prometheus_data:
    driver: local