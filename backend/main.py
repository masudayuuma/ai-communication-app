"""
çµ±åˆAPIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ - ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é€£æº
è¦ä»¶å®šç¾©æ›¸æº–æ‹ : FastAPI + Redis Streams
"""

import asyncio
import time
from typing import Dict, List, Optional
import logging
from datetime import datetime

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response
import redis.asyncio as redis
import httpx
from loguru import logger
from prometheus_client import Counter, Histogram, generate_latest

# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = FastAPI(
    title="AI English Conversation Gateway",
    description="ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆAPI - è¦ä»¶å®šç¾©æ›¸æº–æ‹ ",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
redis_client: Optional[redis.Redis] = None

# è¨­å®š
REDIS_URL = "redis://redis:6379"
WHISPER_SERVICE_URL = "http://whisper:8001"
LLM_SERVICE_URL = "http://llm:8002"
TTS_SERVICE_URL = "http://tts:8003"

# Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹
request_count = Counter('requests_total', 'Total requests', ['method', 'endpoint'])
request_duration = Histogram('request_duration_seconds', 'Request duration')
pipeline_duration = Histogram('pipeline_duration_seconds', 'Pipeline processing time', ['stage'])

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®åˆæœŸåŒ–"""
    global redis_client
    
    logger.info("ğŸš€ AI Conversation Gateway èµ·å‹•ä¸­...")
    
    # Redisæ¥ç¶š
    try:
        redis_client = redis.from_url(REDIS_URL, encoding="utf-8", decode_responses=True)
        await redis_client.ping()
        logger.info("âœ… Redis æ¥ç¶šæˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Redis æ¥ç¶šå¤±æ•—: {e}")
        raise
    
    logger.info("ğŸ‰ AI Conversation Gateway åˆæœŸåŒ–å®Œäº†")

@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    global redis_client
    if redis_client:
        await redis_client.close()
    logger.info("ğŸ‘‹ AI Conversation Gateway çµ‚äº†")

# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

@app.get("/health")
async def health_check():
    """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ - è¦ä»¶å®šç¾©æ›¸æº–æ‹ """
    services_status = {}
    
    # å„ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ç¢ºèª
    services = {
        "whisper": WHISPER_SERVICE_URL,
        "llm": LLM_SERVICE_URL,
        "tts": TTS_SERVICE_URL
    }
    
    for service_name, service_url in services.items():
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{service_url}/health", timeout=5.0)
                services_status[service_name] = response.status_code == 200
        except:
            services_status[service_name] = False
    
    # RedisçŠ¶æ…‹ç¢ºèª
    try:
        await redis_client.ping()
        services_status["redis"] = True
    except:
        services_status["redis"] = False
    
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "services": services_status
    }

@app.get("/metrics")
async def metrics():
    """Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹ - è¦ä»¶å®šç¾©æ›¸æº–æ‹ """
    return Response(generate_latest(), media_type="text/plain")

@app.post("/chat/text")
async def chat_text(request: dict):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ä¼šè©± - LLMã‚µãƒ¼ãƒ“ã‚¹ç›´æ¥å‘¼ã³å‡ºã—"""
    request_count.labels(method="POST", endpoint="/chat/text").inc()
    
    try:
        with request_duration.time():
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{LLM_SERVICE_URL}/generate",
                    json=request,
                    timeout=10.0  # 10ç§’ã«çŸ­ç¸®
                )
                
                if response.status_code == 200:
                    return response.json()
                else:
                    raise HTTPException(status_code=response.status_code, detail="LLMã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼")
                    
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/speech/chat")
async def speech_chat(audio_file: UploadFile = File(...)):
    """
    éŸ³å£°ãƒ™ãƒ¼ã‚¹ã®ä¼šè©± - Redis Streams ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    è¦ä»¶å®šç¾©æ›¸ã®éŸ³å£°å‡¦ç†ãƒ•ãƒ­ãƒ¼ã«æº–æ‹ 
    """
    request_count.labels(method="POST", endpoint="/speech/chat").inc()
    start_time = time.time()
    
    try:
        with request_duration.time():
            # Step 1: Whisper ASRã‚µãƒ¼ãƒ“ã‚¹ã§éŸ³å£°èªè­˜
            with pipeline_duration.labels(stage="asr").time():
                content = await audio_file.read()
                
                async with httpx.AsyncClient() as client:
                    files = {"audio_file": ("audio.wav", content, "audio/wav")}
                    asr_response = await client.post(
                        f"{WHISPER_SERVICE_URL}/transcribe",
                        files=files,
                        timeout=25.0  # éŸ³å£°èªè­˜ç”¨ã«25ç§’ã«å»¶é•·
                    )
                    
                    if asr_response.status_code != 200:
                        raise HTTPException(status_code=500, detail="éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
                    asr_result = asr_response.json()
                    user_text = asr_result.get("transcript", "")
            
            if not user_text.strip():
                logger.warning("âš ï¸ éŸ³å£°èªè­˜çµæœãŒç©º - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§å¿œç­”")
                return {
                    "transcription": "",
                    "response": "Sorry, I couldn't hear you clearly. Could you please try again?",
                    "user_text": "",  # ä¸‹ä½äº’æ›
                    "ai_response": "Sorry, I couldn't hear you clearly. Could you please try again?",  # ä¸‹ä½äº’æ›
                    "conversation_history": [],
                    "asr_confidence": 0.0,
                    "processing_time": time.time() - start_time
                }
            
            # Step 2: LLMã‚µãƒ¼ãƒ“ã‚¹ã§å¿œç­”ç”Ÿæˆ
            with pipeline_duration.labels(stage="llm").time():
                async with httpx.AsyncClient() as client:
                    llm_response = await client.post(
                        f"{LLM_SERVICE_URL}/generate",
                        json={"text": user_text},
                        timeout=15.0  # 15ç§’ã«çŸ­ç¸®
                    )
                    
                    if llm_response.status_code != 200:
                        raise HTTPException(status_code=500, detail="LLMå¿œç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
                    llm_result = llm_response.json()
                    ai_response = llm_result.get("response", "")
            
            # Step 3: TTSã‚µãƒ¼ãƒ“ã‚¹ã§éŸ³å£°åˆæˆ
            with pipeline_duration.labels(stage="tts").time():
                async with httpx.AsyncClient() as client:
                    tts_response = await client.post(
                        f"{TTS_SERVICE_URL}/synthesize",
                        json={"text": ai_response},
                        timeout=15.0  # 15ç§’ã«çŸ­ç¸®
                    )
                    
                    if tts_response.status_code != 200:
                        logger.warning("TTSå¤±æ•— - ãƒ†ã‚­ã‚¹ãƒˆã®ã¿è¿”å´")
                        tts_audio = None
                    else:
                        tts_audio = tts_response.content
            
            # çµæœè¿”å´ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›å½¢å¼ï¼‰
            result = {
                "transcription": user_text,
                "response": ai_response,
                "user_text": user_text,  # ä¸‹ä½äº’æ›
                "ai_response": ai_response,  # ä¸‹ä½äº’æ›
                "conversation_history": llm_result.get("conversation_history", []),
                "asr_confidence": asr_result.get("confidence", 0.0),
                "processing_time": time.time() - start_time
            }
            
            logger.info(f"éŸ³å£°ä¼šè©±å®Œäº†: {user_text[:30]}... â†’ {ai_response[:30]}...")
            return result
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"âŒ éŸ³å£°ä¼šè©±ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹: {error_details}")
        raise HTTPException(status_code=500, detail=f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.post("/api/speech/synthesize")
async def synthesize_speech(request: dict):
    """ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆ - TTSã‚µãƒ¼ãƒ“ã‚¹å‘¼ã³å‡ºã—"""
    request_count.labels(method="POST", endpoint="/speech/synthesize").inc()
    
    try:
        with request_duration.time():
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{TTS_SERVICE_URL}/synthesize",
                    json=request,
                    timeout=10.0  # 10ç§’ã«çŸ­ç¸®
                )
                
                if response.status_code == 200:
                    return Response(
                        content=response.content,
                        media_type="audio/wav",
                        headers={"Content-Disposition": "attachment; filename=speech.wav"}
                    )
                else:
                    raise HTTPException(status_code=response.status_code, detail="TTSç”Ÿæˆã‚¨ãƒ©ãƒ¼")
                    
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/conversation/reset")
async def reset_conversation():
    """ä¼šè©±å±¥æ­´ãƒªã‚»ãƒƒãƒˆ"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(f"{LLM_SERVICE_URL}/reset", timeout=10.0)
            
            if response.status_code == 200:
                return {"message": "ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ"}
            else:
                raise HTTPException(status_code=500, detail="ãƒªã‚»ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                
    except Exception as e:
        logger.error(f"âŒ ä¼šè©±ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Redis Streams ç›£è¦–ï¼ˆå°†æ¥ã®WebSocketå®Ÿè£…ç”¨ï¼‰
async def monitor_streams():
    """Redis Streamsã®ç›£è¦–ï¼ˆWebSocketå®Ÿè£…æ™‚ã«ä½¿ç”¨ï¼‰"""
    logger.info("ğŸ“¡ Redis Streams ç›£è¦–é–‹å§‹")
    # å°†æ¥ã®WebSocketå®Ÿè£…æ™‚ã«ä½¿ç”¨

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)