"""FastAPI backend for AI Communication App."""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
import speech_recognition as sr
import pyttsx3
import requests
import io
import tempfile
import os
import threading
import time
from typing import Optional, List
import base64
import asyncio
from datetime import datetime
from pydub import AudioSegment
from pydub.utils import which

app = FastAPI(title="AI Communication API", version="1.0.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:3002", "http://127.0.0.1:3002"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydanticãƒ¢ãƒ‡ãƒ«
class TextInput(BaseModel):
    text: str

class ChatResponse(BaseModel):
    success: bool
    message: str
    response: Optional[str] = None
    timestamp: str

class TTSRequest(BaseModel):
    text: str

class SystemStatus(BaseModel):
    ollama_connected: bool
    microphone_available: bool
    speaker_available: bool
    available_voices: int
    available_microphones: int

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
conversation_history = []
tts_engine = None

def init_tts_engine():
    """TTS engine ã‚’åˆæœŸåŒ–"""
    global tts_engine
    try:
        tts_engine = pyttsx3.init()
        voices = tts_engine.getProperty('voices')
        if voices:
            for voice in voices:
                if 'english' in voice.name.lower() or 'en_' in voice.id.lower():
                    tts_engine.setProperty('voice', voice.id)
                    break
        tts_engine.setProperty('rate', 180)
        tts_engine.setProperty('volume', 0.9)
        return True
    except Exception as e:
        print(f"TTSåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_ollama_connection():
    """Ollama APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200, response.json() if response.status_code == 200 else None
    except Exception as e:
        return False, str(e)

def generate_ollama_response(prompt: str):
    """Ollama APIã§å¿œç­”ç”Ÿæˆ"""
    try:
        data = {
            "model": "llama3:8b",
            "prompt": prompt,
            "stream": False
        }
        response = requests.post("http://localhost:11434/api/generate", json=data, timeout=30)
        if response.status_code == 200:
            return True, response.json().get("response", "")
        else:
            return False, f"HTTP {response.status_code}"
    except Exception as e:
        return False, str(e)

def convert_audio_to_wav(input_path: str, output_path: str):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVå½¢å¼ã«å¤‰æ›"""
    try:
        # æ§˜ã€…ãªå½¢å¼ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        audio = AudioSegment.from_file(input_path)
        
        # WAVå½¢å¼ã§å‡ºåŠ› (16kHz, ãƒ¢ãƒãƒ©ãƒ«, 16bit)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(output_path, format="wav")
        return True
    except Exception as e:
        print(f"éŸ³å£°å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
        try:
            import shutil
            shutil.copy2(input_path, output_path)
            print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")
            return True
        except Exception as copy_error:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {copy_error}")
            return False

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®åˆæœŸåŒ–"""
    init_tts_engine()
    print("ğŸš€ FastAPI ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸ")

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"message": "AI Communication API", "status": "running"}

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/system/status", response_model=SystemStatus)
async def get_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª"""
    # Ollamaæ¥ç¶šç¢ºèª
    ollama_connected, _ = test_ollama_connection()
    
    # ãƒã‚¤ã‚¯ç¢ºèª
    microphone_available = False
    mic_count = 0
    try:
        mic_list = sr.Microphone.list_microphone_names()
        mic_count = len(mic_list)
        microphone_available = mic_count > 0
    except:
        pass
    
    # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ»éŸ³å£°ç¢ºèª
    speaker_available = tts_engine is not None
    voice_count = 0
    try:
        if tts_engine:
            voices = tts_engine.getProperty('voices')
            voice_count = len(voices) if voices else 0
    except:
        pass
    
    return SystemStatus(
        ollama_connected=ollama_connected,
        microphone_available=microphone_available,
        speaker_available=speaker_available,
        available_voices=voice_count,
        available_microphones=mic_count
    )

@app.post("/chat/text", response_model=ChatResponse)
async def chat_with_text(input_data: TextInput):
    """ãƒ†ã‚­ã‚¹ãƒˆã§AIã¨ä¼šè©±"""
    try:
        success, response = generate_ollama_response(input_data.text)
        
        if success:
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            conversation_entry = {
                "user": input_data.text,
                "ai": response,
                "timestamp": datetime.now().isoformat()
            }
            conversation_history.append(conversation_entry)
            
            return ChatResponse(
                success=True,
                message="å¿œç­”ç”ŸæˆæˆåŠŸ",
                response=response,
                timestamp=datetime.now().isoformat()
            )
        else:
            return ChatResponse(
                success=False,
                message=f"AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {response}",
                timestamp=datetime.now().isoformat()
            )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨ã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.post("/speech/recognize")
async def recognize_speech(audio_file: UploadFile = File(...)):
    """éŸ³å£°èªè­˜"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’åˆ¤å®š
        file_extension = ".webm"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if audio_file.filename:
            if audio_file.filename.endswith('.mp4'):
                file_extension = ".mp4"
            elif audio_file.filename.endswith('.ogg'):
                file_extension = ".ogg"
            elif audio_file.filename.endswith('.wav'):
                file_extension = ".wav"
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_path = temp_file.name
        
        # WAVå½¢å¼ã«å¤‰æ›
        wav_path = temp_path.replace(file_extension, '.wav')
        
        try:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if file_extension == '.wav':
                wav_path = temp_path
                print(f"WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨: {wav_path}")
            else:
                # ä»–ã®å½¢å¼ã®å ´åˆã¯WAVå½¢å¼ã«å¤‰æ›
                if not convert_audio_to_wav(temp_path, wav_path):
                    return {
                        "success": False,
                        "text": "",
                        "message": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ"
                    }
            
            # éŸ³å£°èªè­˜å®Ÿè¡Œ
            r = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio = r.record(source)
                text = r.recognize_google(audio, language="en-US")
                
                return {
                    "success": True,
                    "text": text,
                    "message": "éŸ³å£°èªè­˜æˆåŠŸ"
                }
        
        except sr.UnknownValueError:
            return {
                "success": False,
                "text": "",
                "message": "éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"
            }
        except sr.RequestError as e:
            return {
                "success": False,
                "text": "",
                "message": f"éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}"
            }
        finally:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨ã—ãŸå ´åˆã¯é‡è¤‡å‰Šé™¤ã‚’é¿ã‘ã‚‹
            paths_to_delete = [temp_path] if file_extension == '.wav' else [temp_path, wav_path]
            for path in paths_to_delete:
                if os.path.exists(path):
                    os.unlink(path)
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.post("/speech/synthesize")
async def synthesize_speech(tts_request: TTSRequest):
    """éŸ³å£°åˆæˆ"""
    try:
        if not tts_engine:
            raise HTTPException(status_code=500, detail="TTS engine ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«éŸ³å£°ã‚’ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_path = temp_file.name
        
        # éŸ³å£°åˆæˆå®Ÿè¡Œ
        tts_engine.save_to_file(tts_request.text, temp_path)
        tts_engine.runAndWait()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã¾ã§å°‘ã—å¾…ã¤
        await asyncio.sleep(0.5)
        
        if os.path.exists(temp_path):
            return FileResponse(
                temp_path,
                media_type="audio/wav",
                filename="speech.wav",
                background=lambda: os.unlink(temp_path) if os.path.exists(temp_path) else None
            )
        else:
            raise HTTPException(status_code=500, detail="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.post("/speech/chat")
async def speech_chat(audio_file: UploadFile = File(...)):
    """éŸ³å£°å…¥åŠ›â†’AIå¿œç­”â†’éŸ³å£°å‡ºåŠ›ã®ä¸€æ‹¬å‡¦ç†"""
    try:
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡: filename={audio_file.filename}, content_type={audio_file.content_type}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’åˆ¤å®š
        file_extension = ".webm"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if audio_file.filename:
            if audio_file.filename.endswith('.mp4'):
                file_extension = ".mp4"
            elif audio_file.filename.endswith('.ogg'):
                file_extension = ".ogg"
            elif audio_file.filename.endswith('.wav'):
                file_extension = ".wav"
        
        print(f"ä½¿ç”¨ã™ã‚‹æ‹¡å¼µå­: {file_extension}")
        
        # 1. éŸ³å£°èªè­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_path = temp_file.name
        
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {temp_path}, ã‚µã‚¤ã‚º: {len(content)} bytes")
        
        # WAVå½¢å¼ã«å¤‰æ›
        wav_path = temp_path.replace(file_extension, '.wav')
        
        try:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if file_extension == '.wav':
                wav_path = temp_path
                print(f"WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨: {wav_path}")
            else:
                # ä»–ã®å½¢å¼ã®å ´åˆã¯WAVå½¢å¼ã«å¤‰æ›
                print(f"éŸ³å£°å¤‰æ›é–‹å§‹: {temp_path} -> {wav_path}")
                if not convert_audio_to_wav(temp_path, wav_path):
                    raise HTTPException(status_code=500, detail="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
                print(f"éŸ³å£°å¤‰æ›å®Œäº†")
            
            print(f"éŸ³å£°èªè­˜é–‹å§‹")
            r = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio = r.record(source)
                user_text = r.recognize_google(audio, language="en-US")
                print(f"éŸ³å£°èªè­˜çµæœ: {user_text}")
        finally:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨ã—ãŸå ´åˆã¯é‡è¤‡å‰Šé™¤ã‚’é¿ã‘ã‚‹
            paths_to_delete = [temp_path] if file_extension == '.wav' else [temp_path, wav_path]
            for path in paths_to_delete:
                if os.path.exists(path):
                    print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {path}")
                    os.unlink(path)
        
        # 2. AIå¿œç­”ç”Ÿæˆ
        success, ai_response = generate_ollama_response(user_text)
        
        if not success:
            raise HTTPException(status_code=500, detail=f"AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {ai_response}")
        
        # 3. ä¼šè©±å±¥æ­´ã«è¿½åŠ 
        conversation_entry = {
            "user": user_text,
            "ai": ai_response,
            "timestamp": datetime.now().isoformat()
        }
        conversation_history.append(conversation_entry)
        
        # 4. éŸ³å£°åˆæˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            audio_temp_path = temp_file.name
        
        tts_engine.save_to_file(ai_response, audio_temp_path)
        tts_engine.runAndWait()
        
        await asyncio.sleep(0.5)
        
        return {
            "success": True,
            "user_text": user_text,
            "ai_response": ai_response,
            "audio_url": f"/download/audio/{os.path.basename(audio_temp_path)}",
            "timestamp": datetime.now().isoformat()
        }
    
    except sr.UnknownValueError:
        raise HTTPException(status_code=400, detail="éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    except sr.RequestError as e:
        raise HTTPException(status_code=500, detail=f"éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"éŸ³å£°ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.get("/conversation/history")
async def get_conversation_history():
    """ä¼šè©±å±¥æ­´å–å¾—"""
    return {
        "conversations": conversation_history,
        "total": len(conversation_history)
    }

@app.delete("/conversation/history")
async def clear_conversation_history():
    """ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢"""
    global conversation_history
    conversation_history = []
    return {"message": "ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"}

@app.get("/test/microphone")
async def test_microphone():
    """ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ"""
    try:
        mic_list = sr.Microphone.list_microphone_names()
        return {
            "success": True,
            "microphones": mic_list,
            "count": len(mic_list)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/test/speaker")
async def test_speaker():
    """ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    try:
        test_text = "This is a speaker test. Hello from the AI Communication API."
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_path = temp_file.name
        
        tts_engine.save_to_file(test_text, temp_path)
        tts_engine.runAndWait()
        
        await asyncio.sleep(0.5)
        
        if os.path.exists(temp_path):
            return FileResponse(
                temp_path,
                media_type="audio/wav",
                filename="speaker_test.wav",
                background=lambda: os.unlink(temp_path) if os.path.exists(temp_path) else None
            )
        else:
            raise HTTPException(status_code=500, detail="ãƒ†ã‚¹ãƒˆéŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

@app.post("/test/upload")
async def test_upload(audio_file: UploadFile = File(...)):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    try:
        content = await audio_file.read()
        return {
            "filename": audio_file.filename,
            "content_type": audio_file.content_type,
            "size": len(content),
            "message": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)